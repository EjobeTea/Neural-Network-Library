# Neural-Network-Library
This assignment covers neural networks, backpropagation, and cross-validation techniques.  Made for CSE6363 in Spring 2025.


### Sequential Model
* Use Sequential to chain together layers. The input data will flow through erach layer sequentially.
* Activation functions like ReLU are useful for learning complex patterns, so it is recommended to consider using it in the design.
* After a training loop, use a loss function to find error between model predictions and actual target values, which can be used to update the model's weights as seen in backpropagation.

### Implemented Layers
* Linear
* Sigmoid
* Tanh
* ReLU

### Implemented Loss functions
* Binary Cross Entropy
* MSE
* RMSLE
